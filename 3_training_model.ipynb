{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker  region      charges\n",
       "0   19    1  27.900         0       1       0  16884.92400\n",
       "1   18    0  33.770         1       0       1   1725.55230\n",
       "2   28    0  33.000         3       0       1   4449.46200\n",
       "3   33    0  22.705         0       0       2  21984.47061\n",
       "4   32    0  28.880         0       0       2   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/insurance_data_preprocessed.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 267)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data.sample(frac=0.2, random_state=42)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "train_data = data.drop(test_data.index)\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_data.drop('charges', axis=1).values\n",
    "test_y = test_data['charges'].values\n",
    "\n",
    "train_X = train_data.drop('charges', axis=1).values\n",
    "train_y = train_data['charges'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = DataLoader(torch.Tensor(test_X), batch_size=32)\n",
    "test_y = DataLoader(torch.Tensor(test_y), batch_size=32)\n",
    "\n",
    "train_X = DataLoader(torch.Tensor(train_X), batch_size=32)\n",
    "train_y = DataLoader(torch.Tensor(train_y), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=6, out_features=1, layers=[12, 6]):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.out = nn.Linear(layers[1], out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: -611281.4375 | Test Loss: -1450845.7500\n",
      "Epoch 10 | Train Loss: -2424922368.0000 | Test Loss: -5326841344.0000\n",
      "Epoch 20 | Train Loss: -18137470976.0000 | Test Loss: -39667941376.0000\n",
      "Epoch 30 | Train Loss: -56783122432.0000 | Test Loss: -124007792640.0000\n",
      "Epoch 40 | Train Loss: -124919087104.0000 | Test Loss: -272612769792.0000\n",
      "Epoch 50 | Train Loss: -227140206592.0000 | Test Loss: -495480864768.0000\n",
      "Epoch 60 | Train Loss: -366799323136.0000 | Test Loss: -799908298752.0000\n",
      "Epoch 70 | Train Loss: -546475016192.0000 | Test Loss: -1191507787776.0000\n",
      "Epoch 80 | Train Loss: -768276758528.0000 | Test Loss: -1674871439360.0000\n",
      "Epoch 90 | Train Loss: -1034040705024.0000 | Test Loss: -2253996687360.0000\n",
      "Epoch 100 | Train Loss: -1345453686784.0000 | Test Loss: -2932557742080.0000\n",
      "Epoch 110 | Train Loss: -1704131035136.0000 | Test Loss: -3714072182784.0000\n",
      "Epoch 120 | Train Loss: -2111666388992.0000 | Test Loss: -4602010796032.0000\n",
      "Epoch 130 | Train Loss: -2569649258496.0000 | Test Loss: -5599835193344.0000\n",
      "Epoch 140 | Train Loss: -3079687897088.0000 | Test Loss: -6711049453568.0000\n",
      "Epoch 150 | Train Loss: -3643410219008.0000 | Test Loss: -7939198812160.0000\n",
      "Epoch 160 | Train Loss: -4262467207168.0000 | Test Loss: -9287879360512.0000\n",
      "Epoch 170 | Train Loss: -4938534486016.0000 | Test Loss: -10760737521664.0000\n",
      "Epoch 180 | Train Loss: -5673295282176.0000 | Test Loss: -12361446457344.0000\n",
      "Epoch 190 | Train Loss: -6468467163136.0000 | Test Loss: -14093740146688.0000\n",
      "Epoch 200 | Train Loss: -7325759832064.0000 | Test Loss: -15961349423104.0000\n",
      "Epoch 210 | Train Loss: -8246903439360.0000 | Test Loss: -17968039723008.0000\n",
      "Epoch 220 | Train Loss: -9233636524032.0000 | Test Loss: -20117593260032.0000\n",
      "Epoch 230 | Train Loss: -10287691333632.0000 | Test Loss: -22413783859200.0000\n",
      "Epoch 240 | Train Loss: -11410824232960.0000 | Test Loss: -24860447211520.0000\n",
      "Epoch 250 | Train Loss: -12604775858176.0000 | Test Loss: -27461358190592.0000\n",
      "Epoch 260 | Train Loss: -13871270068224.0000 | Test Loss: -30220287475712.0000\n",
      "Epoch 270 | Train Loss: -15212052742144.0000 | Test Loss: -33141022523392.0000\n",
      "Epoch 280 | Train Loss: -16628872904704.0000 | Test Loss: -36227386441728.0000\n",
      "Epoch 290 | Train Loss: -18123468046336.0000 | Test Loss: -39483160395776.0000\n",
      "Epoch 300 | Train Loss: -19697575657472.0000 | Test Loss: -42912121356288.0000\n",
      "Epoch 310 | Train Loss: -21352926937088.0000 | Test Loss: -46518040002560.0000\n",
      "Epoch 320 | Train Loss: -23091247841280.0000 | Test Loss: -50304687013888.0000\n",
      "Epoch 330 | Train Loss: -24914299977728.0000 | Test Loss: -54275879206912.0000\n",
      "Epoch 340 | Train Loss: -26823750582272.0000 | Test Loss: -58435269820416.0000\n",
      "Epoch 350 | Train Loss: -28821338193920.0000 | Test Loss: -62786650505216.0000\n",
      "Epoch 360 | Train Loss: -30908809740288.0000 | Test Loss: -67333787746304.0000\n",
      "Epoch 370 | Train Loss: -33087872303104.0000 | Test Loss: -72080448028672.0000\n",
      "Epoch 380 | Train Loss: -35360251838464.0000 | Test Loss: -77030347505664.0000\n",
      "Epoch 390 | Train Loss: -37727626067968.0000 | Test Loss: -82187160387584.0000\n",
      "Epoch 400 | Train Loss: -40191662227456.0000 | Test Loss: -87554518941696.0000\n",
      "Epoch 410 | Train Loss: -42754126118912.0000 | Test Loss: -93136265150464.0000\n",
      "Epoch 420 | Train Loss: -45416749989888.0000 | Test Loss: -98936157110272.0000\n",
      "Epoch 430 | Train Loss: -48181165424640.0000 | Test Loss: -104957785145344.0000\n",
      "Epoch 440 | Train Loss: -51049033367552.0000 | Test Loss: -111204731191296.0000\n",
      "Epoch 450 | Train Loss: -54022157369344.0000 | Test Loss: -117680979836928.0000\n",
      "Epoch 460 | Train Loss: -57102131265536.0000 | Test Loss: -124389928468480.0000\n",
      "Epoch 470 | Train Loss: -60290704080896.0000 | Test Loss: -131335435845632.0000\n",
      "Epoch 480 | Train Loss: -63589519982592.0000 | Test Loss: -138521041960960.0000\n",
      "Epoch 490 | Train Loss: -67000277663744.0000 | Test Loss: -145950488133632.0000\n",
      "Epoch 500 | Train Loss: -70524696788992.0000 | Test Loss: -153627473739776.0000\n",
      "Epoch 510 | Train Loss: -74164413136896.0000 | Test Loss: -161555647823872.0000\n",
      "Epoch 520 | Train Loss: -77921133789184.0000 | Test Loss: -169738634264576.0000\n",
      "Epoch 530 | Train Loss: -81796486135808.0000 | Test Loss: -178180006608896.0000\n",
      "Epoch 540 | Train Loss: -85792156286976.0000 | Test Loss: -186883455844352.0000\n",
      "Epoch 550 | Train Loss: -89909855518720.0000 | Test Loss: -195852723290112.0000\n",
      "Epoch 560 | Train Loss: -94151236386816.0000 | Test Loss: -205091348938752.0000\n",
      "Epoch 570 | Train Loss: -98517959835648.0000 | Test Loss: -214603023777792.0000\n",
      "Epoch 580 | Train Loss: -103011728752640.0000 | Test Loss: -224391354908672.0000\n",
      "Epoch 590 | Train Loss: -107634120196096.0000 | Test Loss: -234459848769536.0000\n",
      "Epoch 600 | Train Loss: -112386803499008.0000 | Test Loss: -244812162793472.0000\n",
      "Epoch 610 | Train Loss: -117271842258944.0000 | Test Loss: -255452726165504.0000\n",
      "Epoch 620 | Train Loss: -122290134056960.0000 | Test Loss: -266383636037632.0000\n",
      "Epoch 630 | Train Loss: -127443784433664.0000 | Test Loss: -277609288040448.0000\n",
      "Epoch 640 | Train Loss: -132734731157504.0000 | Test Loss: -289134010695680.0000\n",
      "Epoch 650 | Train Loss: -138163888586752.0000 | Test Loss: -300959699828736.0000\n",
      "Epoch 660 | Train Loss: -143733597143040.0000 | Test Loss: -313091606708224.0000\n",
      "Epoch 670 | Train Loss: -149445316444160.0000 | Test Loss: -325532818341888.0000\n",
      "Epoch 680 | Train Loss: -155300279615488.0000 | Test Loss: -338285951975424.0000\n",
      "Epoch 690 | Train Loss: -161300885798912.0000 | Test Loss: -351356409872384.0000\n",
      "Epoch 700 | Train Loss: -167448527503360.0000 | Test Loss: -364747010605056.0000\n",
      "Epoch 710 | Train Loss: -173744093921280.0000 | Test Loss: -378459935211520.0000\n",
      "Epoch 720 | Train Loss: -180190101635072.0000 | Test Loss: -392500451737600.0000\n",
      "Epoch 730 | Train Loss: -186788580687872.0000 | Test Loss: -406873123586048.0000\n",
      "Epoch 740 | Train Loss: -193539682074624.0000 | Test Loss: -421578118529024.0000\n",
      "Epoch 750 | Train Loss: -200445838491648.0000 | Test Loss: -436621006602240.0000\n",
      "Epoch 760 | Train Loss: -207509650407424.0000 | Test Loss: -452007223623680.0000\n",
      "Epoch 770 | Train Loss: -214731973459968.0000 | Test Loss: -467738581532672.0000\n",
      "Epoch 780 | Train Loss: -222113159970816.0000 | Test Loss: -483816053407744.0000\n",
      "Epoch 790 | Train Loss: -229656145952768.0000 | Test Loss: -500245813264384.0000\n",
      "Epoch 800 | Train Loss: -237363682869248.0000 | Test Loss: -517034269999104.0000\n",
      "Epoch 810 | Train Loss: -245236223705088.0000 | Test Loss: -534181826265088.0000\n",
      "Epoch 820 | Train Loss: -253274087227392.0000 | Test Loss: -551689522249728.0000\n",
      "Epoch 830 | Train Loss: -261480259780608.0000 | Test Loss: -569563867512832.0000\n",
      "Epoch 840 | Train Loss: -269857140506624.0000 | Test Loss: -587810230763520.0000\n",
      "Epoch 850 | Train Loss: -278405954142208.0000 | Test Loss: -606430860148736.0000\n",
      "Epoch 860 | Train Loss: -287127589879808.0000 | Test Loss: -625427701825536.0000\n",
      "Epoch 870 | Train Loss: -296022869803008.0000 | Test Loss: -644803037495296.0000\n",
      "Epoch 880 | Train Loss: -305094511820800.0000 | Test Loss: -664562504302592.0000\n",
      "Epoch 890 | Train Loss: -314345871376384.0000 | Test Loss: -684713417113600.0000\n",
      "Epoch 900 | Train Loss: -323776847806464.0000 | Test Loss: -705255574601728.0000\n",
      "Epoch 910 | Train Loss: -333388951060480.0000 | Test Loss: -726191929556992.0000\n",
      "Epoch 920 | Train Loss: -343182449573888.0000 | Test Loss: -747523689938944.0000\n",
      "Epoch 930 | Train Loss: -353160665235456.0000 | Test Loss: -769257700851712.0000\n",
      "Epoch 940 | Train Loss: -363325946855424.0000 | Test Loss: -791399196786688.0000\n",
      "Epoch 950 | Train Loss: -373680039264256.0000 | Test Loss: -813951935840256.0000\n",
      "Epoch 960 | Train Loss: -384223949094912.0000 | Test Loss: -836917931278336.0000\n",
      "Epoch 970 | Train Loss: -394957139476480.0000 | Test Loss: -860296377794560.0000\n",
      "Epoch 980 | Train Loss: -405882261209088.0000 | Test Loss: -884092845424640.0000\n",
      "Epoch 990 | Train Loss: -417001931538432.0000 | Test Loss: -908313038422016.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for X, y in zip(train_X, train_y):\n",
    "        y_pred = model(X)\n",
    "        loss_train = loss_fn(y_pred.squeeze(), y)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in zip(test_X, test_y):\n",
    "            y_pred = model(X)\n",
    "            loss_test = loss_fn(y_pred.squeeze(), y)\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch} | Train Loss: {loss_train.item():.4f} | Test Loss: {loss_test.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 5708.8672 | Predicted: 30175733760.0000\n",
      "Loss: -172239076982784.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    X, y = next(iter(test_X))[1], next(iter(test_y))[1]\n",
    "    y_pred = model(X)\n",
    "    print(f'Actual: {y.item():.4f} | Predicted: {y_pred.item():.4f}')\n",
    "    loss = loss_fn(y_pred.squeeze(), y)\n",
    "    print(f'Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
